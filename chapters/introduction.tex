% \begin{center}
%   \textbf{\large ТЕХНИЧЕСКОЕ ЗАДАНИЕ}
% \end{center}

% \textbf{Тема:}

% «Разработка мультимодального метода одометрии для мобильных роботов по данным камеры и лидара»

% \textbf{Техническое задание:}

% Рассматривается задача оценки перемещения мобильного робота, конструкция которого предполагает наличие одновременно камеры и лидара. Требуется исследовать и совместить методы визуальной и лидарной одометрии для повышения точности определения траектории движения по сравнению с использованием только одного из датчиков. Базовые методы лидарной и визуальной одометрии, а также метод совмещения данных должны быть выбраны по результатам предварительного анализа. Разработанный прототип необходимо протестировать на открытых наборах данных, в частности на The KITTI Vision Benchmark Suite (Visual Odometry).

% Цель работы — разработать и исследовать мультимодальный алгоритм одометрии, комбинирующий информацию от камеры и лидара, и определить рекомендации по применению такого подхода в робототехнике.

% Задачи:
% \begin{enumerate}
%   \item Проведение аналитического обзора в области методов одометрии на основе данных камеры и лидара, включая способы их синхронизации и комбинирования.
%   \item Выбор подходящего набора методов визуальной и лидарной одометрии и разработка схемы их интеграции.
%   \item Реализация прототипа мультимодального алгоритма одометрии, обеспечивающего оценку движения мобильного робота.
%   \item Проведение серии экспериментов на открытых датасетах, сравнительного анализа полученных результатов с раздельными схемами (только камера / только лидар), а также другими такими представителями мультимодальных методов как SDV-LOAM и GLIM.
%   \item Формирование методических рекомендаций по использованию и настройке полученного решения, включая потенциальные сценарии и ограничения.
% \end{enumerate}

% Требования к разрабатываемому решению:
% \begin{enumerate}
%   \item Разрабатываемая система рассчитана на использование данных монокулярной RGB камеры с разрешением 1382 x 512 и частотой не менее 10 Гц, а также 3D лидара с 64 вертикальными каналами, работающем на частоте не менее 10 Гц.
%   \item Подразумеваются доступными данные калибровки, включающие в себя параметры камеры, а также взаимное расположение камеры и лидара.
%   \item Средняя частота обработки данных должна составлять не менее 8 Гц.
%   \item По результатам серии экспериментов средняя относительная ошибка оценки пройденного пути не должна превышать 2%, а относительная ошибка ориентации – 0.005 град/м на The KITTI Vision Benchmark Suite (Visual Odometry).
%   \item Аппаратные ограничения: объём доступной оперативной памяти не менее 8 ГБ, CPU с частотой 2 ГГц и выше, для обеспечения заявленной скорости обработки.
%   \item Система должна поддерживать логгирование результатов в формате ROS Topics.
%   \item Наличие описания процесса настройки алгоритма, шагов калибровки и воспроизведения экспериментов.
% \end{enumerate}

% Исходные данные:
% \begin{itemize}
%   \item Lee D. et al. LiDAR odometry survey: recent advancements and remaining challenges //Intelligent Service Robotics. – 2024. – Т. 17. – №. 2. – С. 95-118. \cite{lee2024lidar}
%   \item He M. et al. A review of monocular visual odometry //The Visual Computer. – 2020. – Т. 36. – №. 5. – С. 1053-1065. \cite{he2020review}
%   \item Vizzo I. et al. Kiss-icp: In defense of point-to-point icp–simple, accurate, and robust registration if done the right way //IEEE Robotics and Automation Letters. – 2023. – Т. 8. – №. 2. – С. 1029-1036. \cite{vizzo2023kiss}
%   \item Koide K. et al. Glim: 3d range-inertial localization and mapping with gpu-accelerated scan matching factors //Robotics and Autonomous Systems. – 2024. – Т. 179. – С. 104750. \cite{koide2024glim}
%   \item Yuan Z. et al. SDV-LOAM: semi-direct visual–LiDAR Odometry and mapping //IEEE Transactions on Pattern Analysis and Machine Intelligence. – 2023. – Т. 45. – №. 9. – С. 11203-11220. \cite{yuan2023sdv}

% \end{itemize}

% По результатам разработки должен быть представлен программный прототип мультимодального метода одометрии, включающий интегрированную схему работы с данными лидара и камеры, а также отчёт с описанием архитектуры решения, сравнительными экспериментами и методическими рекомендациями по использованию.





\newpage
\renewcommand{\contentsname}{\centerline{\large СОДЕРЖАНИЕ}}
\tableofcontents

\newpage
\begin{center}
  \textbf{\large ВВЕДЕНИЕ}
\end{center}
\addcontentsline{toc}{chapter}{ВВЕДЕНИЕ}

Современные модели машинного обучения демонстрируют высокую эффективность в различных робототехнических задачах, 
но их применение в реальных условиях остается ограниченным, так как среда в реальном мире обычно отличается от той, 
что была использована при обучении. Это делает актуальным вопрос разработки более робастных методов и проведения более полного тестирования обученных моделей.

Однако большинство существующих исследований проводят валидацию моделей в условиях, близких к обучающим, 
что не позволяет сделать выводы, о способности таких моделей адаптироваться под новые условия окружающей среды. 
В качестве решения описанной проблемы, могут выступать методы анализа робастности моделей, позволяющие осуществлять валидацию с варьированием параметров среды.

Целью настоящей работы является разработка и исследование метода анализа робастности обученных моделей к изменениям параметров среды, 
способного выявлять параметры среды, к которым модели наиболее чувствительны, а также прогнозировать эффективность моделей в реальных условиях. В качестве основы для анализа используются обученные модели, 
которые тестируются в симуляционной среде с варьируемыми параметрами, такими как освещение, текстуры, физические свойства объектов и другие факторы.
Результаты работы могут быть использованы для безопасного развертывания моделей на реальных робототехнических системах, а также для разработки более робастных моделей, способных эффективно функционировать в изменяющихся условиях.